# Cross_Modal_Retrieval

A Differentiable Semantic Metric Approximation in Probabilistic Embedding for Cross-Modal Retrieval [\[link\]](https://openreview.net/pdf?id=-KPNRZ8i0ag)

Multi-Lingual Acquisition on Multimodal Pre-training for Cross-modal Retrieval [\[link\]](https://openreview.net/pdf?id=h73nTbImOt9)

Text-Adaptive Multiple Visual Prototype Matching for Video-Text Retrieval [\[link\]](https://openreview.net/pdf?id=XevwsaZ-4z)

Learning with Noisy Correspondence for Cross-modal Matching [\[link\]](https://openreview.net/forum?id=S9ZyhWC17wJ)

CodeCMR: Cross-Modal Retrieval For Function-Level Binary Source Code Matching [\[link\]](https://nips.cc/virtual/2020/public/poster_285f89b802bcb2651801455c86d78f2a.html)

Everything at Once – Multi-modal Fusion Transformer for Video Retrieval [\[link\]](https://openaccess.thecvf.com/content/CVPR2022/papers/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.pdf)

Cross Modal Retrieval with Querybank Normalisation [\[link\]](https://openaccess.thecvf.com/content/CVPR2022/papers/Bogolin_Cross_Modal_Retrieval_With_Querybank_Normalisation_CVPR_2022_paper.pdf)

EI-CLIP: Entity-aware Interventional Contrastive Learning for E-commerce Cross-modal Retrieval [\[link\]](https://openaccess.thecvf.com/content/CVPR2022/papers/Ma_EI-CLIP_Entity-Aware_Interventional_Contrastive_Learning_for_E-Commerce_Cross-Modal_Retrieval_CVPR_2022_paper.pdf)

COTS: Collaborative Two-Stream Vision-Language Pre-Training Model for Cross-Modal Retrieval [\[link\]](https://openaccess.thecvf.com/content/CVPR2022/papers/Lu_COTS_Collaborative_Two-Stream_Vision-Language_Pre-Training_Model_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf)

ViSTA: Vision and Scene Text Aggregation for Cross-Modal Retrieval [\[link\]](https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_ViSTA_Vision_and_Scene_Text_Aggregation_for_Cross-Modal_Retrieval_CVPR_2022_paper.pdf)

X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval [\[link\]](https://openaccess.thecvf.com/content/CVPR2022/papers/Gorti_X-Pool_Cross-Modal_Language-Video_Attention_for_Text-Video_Retrieval_CVPR_2022_paper.pdf)

Probabilistic Embeddings for Cross-Modal Retrieval[\[link\]](https://openaccess.thecvf.com/content/CVPR2021/papers/Chun_Probabilistic_Embeddings_for_Cross-Modal_Retrieval_CVPR_2021_paper.pdf)

Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval[\[link\]](https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_Adaptive_Cross-Modal_Prototypes_for_Cross-Domain_Visual-Language_Retrieval_CVPR_2021_paper.pdf)

Learning Cross-Modal Retrieval with Noisy Labels[\[link\]](https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Learning_Cross-Modal_Retrieval_With_Noisy_Labels_CVPR_2021_paper.pdf)

https://openaccess.thecvf.com/content/CVPR2021/papers/Jing_Cross-Modal_Center_Loss_for_3D_Cross-Modal_Retrieval_CVPR_2021_paper.pdf

https://openaccess.thecvf.com/content/CVPR2021/papers/Salvador_Revamping_Cross-Modal_Recipe_Retrieval_With_Hierarchical_Transformers_and_Self-Supervised_Learning_CVPR_2021_paper.pdf

https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_IMRAM_Iterative_Matching_With_Recurrent_Attention_Memory_for_Cross-Modal_Image-Text_CVPR_2020_paper.pdf

https://openaccess.thecvf.com/content_CVPR_2020/papers/Pang_Solving_Mixed-Modal_Jigsaw_Puzzle_for_Fine-Grained_Sketch-Based_Image_Retrieval_CVPR_2020_paper.pdf

https://openaccess.thecvf.com/content/ICCV2021/papers/Cai_AskConfirm_Active_Detail_Enriching_for_Cross-Modal_Retrieval_With_Partial_Query_ICCV_2021_paper.pdf

https://openaccess.thecvf.com/content/ICCV2021/papers/Lin_Single_Image_3D_Shape_Retrieval_via_Cross-Modal_Instance_and_Category_ICCV_2021_paper.pdf

https://openaccess.thecvf.com/content/ICCV2021/papers/Zhan_Product1M_Towards_Weakly_Supervised_Instance-Level_Product_Retrieval_via_Cross-Modal_Pretraining_ICCV_2021_paper.pdf

https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Wasserstein_Coupled_Graph_Learning_for_Cross-Modal_Retrieval_ICCV_2021_paper.pdf

ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound

VTC: Improving Video-Text Retrieval with User Comments

Dual-Stream Knowledge-Preserving Hashing for Unsupervised Video Retrieval

MILES: Visual BERT Pre-training with Injected Language Semantics for Video-text Retrieval

Multi-Query Video Retrieval

Selective Query-guided Debiasing for Video Corpus Moment Retrieval

TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval

Learning Linguistic Association Towards Efficient Text-Video Retrieval

Deep Hash Distillation for Image Retrieval

Lightweight Attentional Feature Fusion: A New Baseline for Text-to-Video Retrieval

CODER: Coupled Diversity-Sensitive Momentum Contrastive Learning for Image-Text Retrieval

A Sketch Is Worth a Thousand Words:Image Retrieval with Text and Sketch

LWGNet – Learned Wirtinger Gradients for Fourier Ptychographic Phase Retrieval

Multi-modal Transformer for Video Retrieval

Preserving Semantic Neighborhoods for Robust Cross-modal Retrieval

Learning Joint Visual Semantic Matching Embeddings for Language-guided Retrieval

SOLAR: Second-Order Loss and Attention for Image Retrieval

VLANet: Video-Language Alignment Network for Weakly-Supervised Video Moment Retrieval
